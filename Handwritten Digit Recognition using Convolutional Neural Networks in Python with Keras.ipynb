{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the MNIST dataset in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras deep learning library provides a convenience method for loading the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# To demonstrate how easy it is to load the MNIST dataset, we will first write a little script to download and visualize the first 4 images in the training dataset.\n",
    "\n",
    "# Plot ad hoc mnist instances\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model with Multi-Layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Keras libraries \n",
    "import numpy\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for ensuring reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1 scale\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Baseline Function for Multi-Layer-Perceptron Model\n",
    "def model_mlp():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim =num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile Model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.2811 - acc: 0.9206 - val_loss: 0.1413 - val_acc: 0.9576\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1117 - acc: 0.9676 - val_loss: 0.0916 - val_acc: 0.9715\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0714 - acc: 0.9798 - val_loss: 0.0779 - val_acc: 0.9774\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0501 - acc: 0.9858 - val_loss: 0.0736 - val_acc: 0.9770\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0369 - acc: 0.9893 - val_loss: 0.0673 - val_acc: 0.9787\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0266 - acc: 0.9930 - val_loss: 0.0634 - val_acc: 0.9803\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0208 - acc: 0.9947 - val_loss: 0.0605 - val_acc: 0.9814\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0138 - acc: 0.9971 - val_loss: 0.0600 - val_acc: 0.9814\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0563 - val_acc: 0.9816\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0568 - val_acc: 0.9815\n",
      "baseline Error:  2%\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = model_mlp()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"baseline Error: %2.f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Simple Convolutional Neural Network for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our Convolutional Neural Network Model.\n",
    "\n",
    "1. The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above [pixels][width][height].\n",
    "2. Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    "3. The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "4. Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
    "5. Next a fully connected layer with 128 neurons and rectifier activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the rest of the libraries for CNN\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to load the MNIST dataset and reshape it so that it is suitable for use training a CNN.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels] [width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# One Hot Endoing outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function for CNN\n",
    "def model_simple_cnn():\n",
    "    # create cnn model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5,5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # complie model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dheer\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 38s - loss: 0.2431 - acc: 0.9309 - val_loss: 0.0700 - val_acc: 0.9783\n",
      "Epoch 2/10\n",
      " - 37s - loss: 0.0695 - acc: 0.9794 - val_loss: 0.0468 - val_acc: 0.9851\n",
      "Epoch 3/10\n",
      " - 36s - loss: 0.0496 - acc: 0.9853 - val_loss: 0.0371 - val_acc: 0.9883\n",
      "Epoch 4/10\n",
      " - 36s - loss: 0.0378 - acc: 0.9880 - val_loss: 0.0349 - val_acc: 0.9885\n",
      "Epoch 5/10\n",
      " - 36s - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0453 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      " - 38s - loss: 0.0254 - acc: 0.9920 - val_loss: 0.0360 - val_acc: 0.9871\n",
      "Epoch 7/10\n",
      " - 36s - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0356 - val_acc: 0.9888\n",
      "Epoch 8/10\n",
      " - 36s - loss: 0.0187 - acc: 0.9940 - val_loss: 0.0328 - val_acc: 0.9890\n",
      "Epoch 9/10\n",
      " - 36s - loss: 0.0163 - acc: 0.9944 - val_loss: 0.0391 - val_acc: 0.9875\n",
      "Epoch 10/10\n",
      " - 41s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0302 - val_acc: 0.9902\n",
      "CNN Error:  1%\n"
     ]
    }
   ],
   "source": [
    "# Building CNN model\n",
    "model = model_simple_cnn()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Final Evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %2.f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Larger Convolutional Neural Network for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a large CNN architecture with additional convolutional, max pooling layers and fully connected layers. The network topology can be summarized as follows.\n",
    "\n",
    "1. Convolutional layer with 30 feature maps of size 5×5.\n",
    "2. Pooling layer taking the max over 2*2 patches.\n",
    "3. Convolutional layer with 15 feature maps of size 3×3.\n",
    "4. Pooling layer taking the max over 2*2 patches.\n",
    "5. Dropout layer with a probability of 20%.\n",
    "6. Flatten layer.\n",
    "7. Fully connected layer with 128 neurons and rectifier activation.\n",
    "8. Fully connected layer with 50 neurons and rectifier activation.\n",
    "9. Output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Function for Larger CNN Model\n",
    "def model_larger_cnn():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5,5), input_shape=(1,28,28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(15, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.3785 - acc: 0.8876 - val_loss: 0.0783 - val_acc: 0.9758\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0978 - acc: 0.9699 - val_loss: 0.0577 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0715 - acc: 0.9781 - val_loss: 0.0436 - val_acc: 0.9853\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0593 - acc: 0.9816 - val_loss: 0.0343 - val_acc: 0.9885\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0496 - acc: 0.9843 - val_loss: 0.0324 - val_acc: 0.9889\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0450 - acc: 0.9863 - val_loss: 0.0324 - val_acc: 0.9893\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0398 - acc: 0.9873 - val_loss: 0.0272 - val_acc: 0.9906\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0359 - acc: 0.9890 - val_loss: 0.0286 - val_acc: 0.9902\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0335 - acc: 0.9894 - val_loss: 0.0236 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0299 - acc: 0.9898 - val_loss: 0.0268 - val_acc: 0.9907\n",
      "larger CNN Error: 0.93%\n"
     ]
    }
   ],
   "source": [
    "# Building the Larger CNN Model\n",
    "model = model_larger_cnn()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"larger CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
